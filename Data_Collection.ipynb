{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import configparser\n",
    "import urllib.parse\n",
    "from urllib.error import HTTPError\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all titles from the container and put into list all_titles\n",
    "def titles(movies_container):\n",
    "    \"\"\"Returns list of movie titles from IMDB search results.\"\"\"\n",
    "    all_titles = [h3.find('a').get_text() for h3 in movies_container.findAll('h3')]\n",
    "    return all_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all ratings from container and put into mpaa_ratings list\n",
    "#if no rating exists, put NaN\n",
    "def mpaa_ratings(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie MPAA ratings from IMDB search results.\"\"\"\n",
    "    mpaa_ratings = []\n",
    "    for movie in imdb_movie_list:\n",
    "        rating = movie.find('span', class_='certificate')\n",
    "        if rating:\n",
    "            mpaa_ratings.append(rating.get_text())\n",
    "        else:\n",
    "            mpaa_ratings.append(\"NaN\")\n",
    "    return mpaa_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all runtime from container and put into all_runtimes list\n",
    "#if no runtimes exists, put NaN\n",
    "def runtimes(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie runtimes from IMDB search results.\"\"\"\n",
    "    all_runtimes = []\n",
    "    for movie in imdb_movie_list:\n",
    "        runtime = movie.find('span', class_='runtime')\n",
    "        if runtime:\n",
    "            all_runtimes.append(runtime.get_text())\n",
    "        else:\n",
    "            all_runtimes.append(\"NaN\")\n",
    "    return all_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all genres from container and put into all_genres list\n",
    "#if no genres exists, put NaN\n",
    "def genres(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie genres from IMDB search results.\"\"\"\n",
    "    all_genres = []\n",
    "    for movie in imdb_movie_list:\n",
    "        genre = movie.find('span', class_='genre')\n",
    "        if genre:\n",
    "            all_genres.append(genre.get_text())\n",
    "        else:\n",
    "            all_genres.append(\"NaN\")\n",
    "    all_genres = [genre.strip() for genre in all_genres]\n",
    "    return all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_id(imdb_movie_list):\n",
    "    \"\"\"Returns list of IMDB IDs for movies from IMDB search results.\"\"\"\n",
    "    all_ids = []\n",
    "    for movie in imdb_movie_list:\n",
    "        header = movie.find('h3', class_=\"lister-item-header\")\n",
    "        xid = header.find('a').attrs['href']\n",
    "        xid = xid.lstrip('/title/')\n",
    "        xid = xid.rstrip('/')\n",
    "        xid = \"tt\"+xid\n",
    "        all_ids.append(xid)\n",
    "    return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all star ratings from container and put into star_ratings list\n",
    "#if no star ratings exists, put NaN\n",
    "def star_ratings(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie ratings from IMDB search results.\"\"\"\n",
    "    star_ratings = []\n",
    "    for movie in imdb_movie_list:\n",
    "        rating = movie.find('strong')\n",
    "        if rating:\n",
    "            star_ratings.append(rating.get_text())\n",
    "        else:\n",
    "            star_ratings.append(\"NaN\")\n",
    "    return star_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key(config_file):\n",
    "    \"\"\"Returns API key from config file\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    api_key = config['API']['apikey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_imdb_data(imdb_seach_url, total_results):\n",
    "    \"\"\"Returns tuple of lists in format below for given IMDB search results: \n",
    "    (titles, MPAA ratings, runtimes, genres, star ratings, IMDB IDs)\n",
    "    Expect this function to take (total_results/50)/2 seconds.\n",
    "    Total results should be less than 10,000.\"\"\"\n",
    "    #initialize all lists\n",
    "    all_titles = []\n",
    "    all_mpaa_ratings = []\n",
    "    all_runtimes = []\n",
    "    all_genres = []\n",
    "    all_star_ratings = []\n",
    "    all_ids = []\n",
    "    #create soup for first page\n",
    "    html_page = requests.get(imdb_seach_url)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    #create containers for first page\n",
    "    movies_container = soup.find('div', class_=\"lister-list\")\n",
    "    imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "    #collect first page data\n",
    "    for title in titles(movies_container):\n",
    "        all_titles.append(title)\n",
    "    for rating in mpaa_ratings(imdb_movie_list):\n",
    "        all_mpaa_ratings.append(rating)\n",
    "    for runtime in runtimes(imdb_movie_list):\n",
    "        all_runtimes.append(runtime)\n",
    "    for genre in genres(imdb_movie_list):\n",
    "        all_genres.append(genre)\n",
    "    for rating in star_ratings(imdb_movie_list):\n",
    "        all_star_ratings.append(rating)\n",
    "    for xid in imdb_id(imdb_movie_list):\n",
    "        all_ids.append(xid)\n",
    "    #check if total_results is greater than 10,000 since the IMDB URL changes after that many results\n",
    "    if total_results > 10_000:\n",
    "        print(\"The amount of results is too large, this function can only support up to 10,000. Collecting data for top 10,000 results only.\")\n",
    "        total_results = 10_001\n",
    "    #iterate through the rest of the results to collect data\n",
    "    for i in range(51,total_results,50):\n",
    "        #create soup for current page\n",
    "        url = imdb_seach_url+\"&start={i}&ref_=adv_nxt\"\n",
    "        html_page = requests.get(url)\n",
    "        soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "        #create containers for current page\n",
    "        movies_container = soup.find('div', class_=\"lister-list\")\n",
    "        imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "        #collect current page data\n",
    "        for title in titles(movies_container):\n",
    "            all_titles.append(title)\n",
    "        for rating in mpaa_ratings(imdb_movie_list):\n",
    "            all_mpaa_ratings.append(rating)\n",
    "        for runtime in runtimes(imdb_movie_list):\n",
    "            all_runtimes.append(runtime)\n",
    "        for genre in genres(imdb_movie_list):\n",
    "            all_genres.append(genre)\n",
    "        for rating in star_ratings(imdb_movie_list):\n",
    "            all_star_ratings.append(rating)\n",
    "        for xid in imdb_id(imdb_movie_list):\n",
    "            all_ids.append(xid)\n",
    "        #buffer for half a second so as to not DDOS IMDB\n",
    "        time.sleep(0.5)\n",
    "    return all_titles, all_mpaa_ratings, all_runtimes, all_genres, all_star_ratings, all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_movie_data(imdb_seach_url, total_results, config_file):\n",
    "    \"\"\"Returns a dictionary of detailed movie data for given IMDB search results.\n",
    "    Expect this function to take (total_results/2)+((total_results/50)/2) seconds.\n",
    "    Total results should be less than 10,000.\"\"\"\n",
    "    #call function to collect IMDB data\n",
    "    imdb_data = collect_imdb_data(imdb_seach_url, total_results)\n",
    "    #assign IMDB ID data to list\n",
    "    all_ids = imdb_data[5]\n",
    "    #initialize lists\n",
    "    all_budgets = []\n",
    "    all_revenues = []\n",
    "    #call function to get api key\n",
    "    api_key = get_api_key(config_file)\n",
    "    #iterate through all IDs collected from IMDB\n",
    "    for xid in all_ids:\n",
    "        #try-except block to catch any pages which return an HTTP error\n",
    "        try:\n",
    "            movie_id = None\n",
    "            budget = None\n",
    "            revenue = None\n",
    "            #use API to get movie information from The Movie DB using the IMDB ID\n",
    "            url = f\"https://api.themoviedb.org/3/find/{xid}?api_key={api_key}&language=en-US&external_source=imdb_id\"\n",
    "            data = json.load(urllib.request.urlopen(url))\n",
    "            #iterate through movie results in the data received from API\n",
    "            for result in data['movie_results']:\n",
    "                #if the movie ID field exists\n",
    "                if result['id']:\n",
    "                    #use movie ID in API to get detailed movie information\n",
    "                    movie_id = result['id']\n",
    "                    new_url = f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}&language=en-US\"\n",
    "                    new_data = json.load(urllib.request.urlopen(new_url))\n",
    "                    budget = new_data['budget']\n",
    "                    revenue = new_data['revenue']\n",
    "                else:\n",
    "                    #else, set values to null\n",
    "                    movie_id = \"NaN\"\n",
    "                    budget = \"NaN\"\n",
    "                    revenue = \"NaN\"\n",
    "        except HTTPError as err:\n",
    "            #if there is an HTTP error, set values to null and continue\n",
    "            movie_id = \"NaN\"\n",
    "            budget = \"NaN\"\n",
    "            revenue = \"NaN\"\n",
    "            all_budgets.append(budget)\n",
    "            all_revenues.append(revenue)\n",
    "            #buffer for half a second \n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "        #if the try block succeeded, add values to lists and \n",
    "        all_budgets.append(budget)\n",
    "        all_revenues.append(revenue)\n",
    "        #buffer for half a second \n",
    "        time.sleep(0.5)\n",
    "    #store all movie data collected in a dictionary\n",
    "    movie_data_dictionary = {'movie_id': all_ids, 'movie_title': imdb_data[0], 'mpaa_rating': imdb_data[1], 'runtime': imdb_data[2], 'genre': imdb_data[3], 'star_rating': imdb_data[4], 'gross_revenue': all_revenues, 'budget': all_budgets}\n",
    "    return movie_data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use functions above to create a dataframe of movie data and save this data to a CSV file.\n",
    "url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2019-12-31\"\n",
    "config_file = \"config.py\"\n",
    "\n",
    "movie_dict = collect_movie_data(url, 10_001, config_file)\n",
    "movie_df = pd.DataFrame(movie_dict)\n",
    "movie_df.to_csv('movie_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
