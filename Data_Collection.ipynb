{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import configparser\n",
    "import urllib.parse\n",
    "from urllib.error import HTTPError\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used for collecting individual fields of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below each return a specific field of data from the IMDB search result list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all titles from the container and put into list all_titles\n",
    "def titles(movies_container):\n",
    "    \"\"\"Returns list of movie titles from IMDB search results.\"\"\"\n",
    "    all_titles = [h3.find('a').get_text() for h3 in movies_container.findAll('h3')]\n",
    "    return all_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all ratings from container and put into mpaa_ratings list\n",
    "#if no rating exists, put NaN\n",
    "def mpaa_ratings(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie MPAA ratings from IMDB search results.\"\"\"\n",
    "    mpaa_ratings = []\n",
    "    for movie in imdb_movie_list:\n",
    "        rating = movie.find('span', class_='certificate')\n",
    "        if rating:\n",
    "            mpaa_ratings.append(rating.get_text())\n",
    "        else:\n",
    "            mpaa_ratings.append(\"NaN\")\n",
    "    return mpaa_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all runtime from container and put into all_runtimes list\n",
    "#if no runtimes exists, put NaN\n",
    "def runtimes(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie runtimes from IMDB search results.\"\"\"\n",
    "    all_runtimes = []\n",
    "    for movie in imdb_movie_list:\n",
    "        runtime = movie.find('span', class_='runtime')\n",
    "        if runtime:\n",
    "            all_runtimes.append(runtime.get_text())\n",
    "        else:\n",
    "            all_runtimes.append(\"NaN\")\n",
    "    return all_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all genres from container and put into all_genres list\n",
    "#if no genres exists, put NaN\n",
    "def genres(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie genres from IMDB search results.\"\"\"\n",
    "    all_genres = []\n",
    "    for movie in imdb_movie_list:\n",
    "        genre = movie.find('span', class_='genre')\n",
    "        if genre:\n",
    "            all_genres.append(genre.get_text())\n",
    "        else:\n",
    "            all_genres.append(\"NaN\")\n",
    "    all_genres = [genre.strip() for genre in all_genres]\n",
    "    return all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_id(imdb_movie_list):\n",
    "    \"\"\"Returns list of IMDB IDs for movies from IMDB search results.\"\"\"\n",
    "    all_ids = []\n",
    "    for movie in imdb_movie_list:\n",
    "        header = movie.find('h3', class_=\"lister-item-header\")\n",
    "        xid = header.find('a').attrs['href']\n",
    "        xid = xid.lstrip('/title/')\n",
    "        xid = xid.rstrip('/')\n",
    "        xid = \"tt\"+xid\n",
    "        all_ids.append(xid)\n",
    "    return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all star ratings from container and put into star_ratings list\n",
    "#if no star ratings exists, put NaN\n",
    "def star_ratings(imdb_movie_list):\n",
    "    \"\"\"Returns list of movie ratings from IMDB search results.\"\"\"\n",
    "    star_ratings = []\n",
    "    for movie in imdb_movie_list:\n",
    "        rating = movie.find('strong')\n",
    "        if rating:\n",
    "            star_ratings.append(rating.get_text())\n",
    "        else:\n",
    "            star_ratings.append(\"NaN\")\n",
    "    return star_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for grabbing API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a way to grab the API key from the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key(config_file):\n",
    "    \"\"\"Returns API key from config file\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    api_key = config['API']['apikey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for gathering field data into a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the URL for an IMDB search, this function navigates to the page and calls functions to collect all fields. The first page in the search results needs to have data collected first as the URL changes for all other pages. We then iterate through every other page and run the functions again. To avoid getting blocked by these databases, we add a buffer of 0.5 seconds to each loop. This is what makes the function take a bit to run. With the max amount of results allowed, 10,000, the function should take around 100 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_imdb_data(imdb_seach_url, total_results):\n",
    "    \"\"\"Returns tuple of lists in format below for given IMDB search results: \n",
    "    (titles, MPAA ratings, runtimes, genres, star ratings, IMDB IDs)\n",
    "    Expect this function to take (total_results/50)/2 seconds.\n",
    "    Total results should be less than 10,000.\"\"\"\n",
    "    #initialize all lists\n",
    "    all_titles = []\n",
    "    all_mpaa_ratings = []\n",
    "    all_runtimes = []\n",
    "    all_genres = []\n",
    "    all_star_ratings = []\n",
    "    all_ids = []\n",
    "    #create soup for first page\n",
    "    html_page = requests.get(imdb_seach_url)\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    #create containers for first page\n",
    "    movies_container = soup.find('div', class_=\"lister-list\")\n",
    "    imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "    #collect first page data\n",
    "    for title in titles(movies_container):\n",
    "        all_titles.append(title)\n",
    "    for rating in mpaa_ratings(imdb_movie_list):\n",
    "        all_mpaa_ratings.append(rating)\n",
    "    for runtime in runtimes(imdb_movie_list):\n",
    "        all_runtimes.append(runtime)\n",
    "    for genre in genres(imdb_movie_list):\n",
    "        all_genres.append(genre)\n",
    "    for rating in star_ratings(imdb_movie_list):\n",
    "        all_star_ratings.append(rating)\n",
    "    for xid in imdb_id(imdb_movie_list):\n",
    "        all_ids.append(xid)\n",
    "    #check if total_results is greater than 10,000 since the IMDB URL changes after that many results\n",
    "    if total_results > 10_000:\n",
    "        print(\"The amount of results is too large, this function can only support up to 10,000. Collecting data for top 10,000 results only.\")\n",
    "        total_results = 10_001\n",
    "    #iterate through the rest of the results to collect data\n",
    "    for i in range(51,total_results,50):\n",
    "        #create soup for current page\n",
    "        url = imdb_seach_url+\"&start={i}&ref_=adv_nxt\"\n",
    "        html_page = requests.get(url)\n",
    "        soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "        #create containers for current page\n",
    "        movies_container = soup.find('div', class_=\"lister-list\")\n",
    "        imdb_movie_list = movies_container.findAll('div', class_=\"lister-item-content\")\n",
    "        #collect current page data\n",
    "        for title in titles(movies_container):\n",
    "            all_titles.append(title)\n",
    "        for rating in mpaa_ratings(imdb_movie_list):\n",
    "            all_mpaa_ratings.append(rating)\n",
    "        for runtime in runtimes(imdb_movie_list):\n",
    "            all_runtimes.append(runtime)\n",
    "        for genre in genres(imdb_movie_list):\n",
    "            all_genres.append(genre)\n",
    "        for rating in star_ratings(imdb_movie_list):\n",
    "            all_star_ratings.append(rating)\n",
    "        for xid in imdb_id(imdb_movie_list):\n",
    "            all_ids.append(xid)\n",
    "        #buffer for half a second so as to not DDOS IMDB\n",
    "        time.sleep(0.5)\n",
    "    return all_titles, all_mpaa_ratings, all_runtimes, all_genres, all_star_ratings, all_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below uses The Movie DB's API to collect the last of the data, revenue and budget. To do this, it uses the IMDB movie IDs to first find the movie in TMDB's database. This gives us the movie's ID for this database and allows us to avoid having mismatched movie results that we may see by using movie title. Next, it takes the TMDB movie ID and uses it to find the movie's details. Inside the movie's details are the fields we are looking for.\n",
    "\n",
    "The function returns a dictionary storing our field lists, which can then easily be used to build a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_movie_data(imdb_seach_url, total_results, config_file):\n",
    "    \"\"\"Returns a dictionary of detailed movie data for given IMDB search results.\n",
    "    Expect this function to take (total_results/2)+((total_results/50)/2) seconds.\n",
    "    Total results should be less than 10,000.\"\"\"\n",
    "    #call function to collect IMDB data\n",
    "    imdb_data = collect_imdb_data(imdb_seach_url, total_results)\n",
    "    #assign IMDB ID data to list\n",
    "    all_ids = imdb_data[5]\n",
    "    #initialize lists\n",
    "    all_budgets = []\n",
    "    all_revenues = []\n",
    "    #call function to get api key\n",
    "    api_key = get_api_key(config_file)\n",
    "    #iterate through all IDs collected from IMDB\n",
    "    for xid in all_ids:\n",
    "        #try-except block to catch any pages which return an HTTP error\n",
    "        try:\n",
    "            movie_id = None\n",
    "            budget = None\n",
    "            revenue = None\n",
    "            #use API to get movie information from The Movie DB using the IMDB ID\n",
    "            url = f\"https://api.themoviedb.org/3/find/{xid}?api_key={api_key}&language=en-US&external_source=imdb_id\"\n",
    "            data = json.load(urllib.request.urlopen(url))\n",
    "            #iterate through movie results in the data received from API\n",
    "            for result in data['movie_results']:\n",
    "                #if the movie ID field exists\n",
    "                if result['id']:\n",
    "                    #use movie ID in API to get detailed movie information\n",
    "                    movie_id = result['id']\n",
    "                    new_url = f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}&language=en-US\"\n",
    "                    new_data = json.load(urllib.request.urlopen(new_url))\n",
    "                    budget = new_data['budget']\n",
    "                    revenue = new_data['revenue']\n",
    "                else:\n",
    "                    #else, set values to null\n",
    "                    movie_id = \"NaN\"\n",
    "                    budget = \"NaN\"\n",
    "                    revenue = \"NaN\"\n",
    "        except HTTPError as err:\n",
    "            #if there is an HTTP error, set values to null and continue\n",
    "            movie_id = \"NaN\"\n",
    "            budget = \"NaN\"\n",
    "            revenue = \"NaN\"\n",
    "            all_budgets.append(budget)\n",
    "            all_revenues.append(revenue)\n",
    "            #buffer for half a second \n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "        #if the try block succeeded, add values to lists and \n",
    "        all_budgets.append(budget)\n",
    "        all_revenues.append(revenue)\n",
    "        #buffer for half a second \n",
    "        time.sleep(0.5)\n",
    "    #store all movie data collected in a dictionary\n",
    "    movie_data_dictionary = {'movie_id': all_ids, 'movie_title': imdb_data[0], 'mpaa_rating': imdb_data[1], 'runtime': imdb_data[2], 'genre': imdb_data[3], 'star_rating': imdb_data[4], 'gross_revenue': all_revenues, 'budget': all_budgets}\n",
    "    return movie_data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataframe and storing it into a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can call our function for collecting movie data and store the returned dictionary into `movie_dict`. This dictionary is used to make our DataFrame, which we then store into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use functions above to create a dataframe of movie data and save this data to a CSV file.\n",
    "url = \"https://www.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2019-12-31\"\n",
    "config_file = \"config.py\"\n",
    "\n",
    "movie_dict = collect_movie_data(url, 10_001, config_file)\n",
    "movie_df = pd.DataFrame(movie_dict)\n",
    "movie_df.to_csv('movie_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
